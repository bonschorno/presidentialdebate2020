---
title: Analyzing the first 2020 presidential debate
subtitle: A text mining approach by @bonschorno
output: rolldown::scrollama
---

```{css, echo=FALSE}
.level1 {
  min-height: 400px;
  margin-bottom: 4em;
  padding: 1em 1em 1em;
}
.is-active {
  background-color: lightgrey;
}
body {
  margin-bottom: 80vh;
  background-color: lightgrey;
  font-family: "Trebuchet MS";
}
```

```{r setup, include=FALSE, echo=FALSE}
library(haven) #for importing spss files
library(tidyverse) #for everything else
library(knitr)
library(plotly)
library(quanteda)
library(patchwork)
library(extrafont)

knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
```

**Repository**: Link | **Contact**: You can find me on Twitter or write me an e-mail.

## Intro {-}

I must admit I did not watch the debate between the two presidential candidates. But it seems that I didn't miss anything either. All the major American newspapers concluded that the discussion rapidly turned into chaos. The Times in London concluded: "The clearest loser of this first presidential debate between Donald Trump and Joe Biden was America" (Source: [The Times](https://www.thetimes.co.uk/article/us-presidential-debate-donald-trump-launches-tirade-of-personal-attacks-on-joe-biden-in-chaotic-debate-jfmwxjmqj)).

So, after CNN's Dana Bash calling the debate a "shitshow" (Source: [CNN](https://www.realclearpolitics.com/video/2020/09/29/cnns_dana_bash_debate_was_a_shitshow.html)), I wanted to analyze it myself and web scraped the [USA Today](https://eu.usatoday.com/story/news/politics/elections/2020/09/30/presidential-debate-read-full-transcript-first-debate/3587462001/) page that published the meticulously transcribed debate a few days ago. I scraped the website using the `rvest` package; for the data wrangling and visualizations, I used the different packages from the `tidyverse.` More advanced visualizations like the "keyness"-plot were created using the `quanteda` package. 

Some caveats at the beginning. For simplicity's sake, some issues are not flawlessly coded. For example, a statement by presidential candidate Biden is not included because it was awkwardly embedded in the HTML document and its exclusion greatly simplified the code. Also, for the descriptive plots at the beginning, I counted the number of words only in a crude way and did not remove the stopwords. I do not assume that this has a strong influence on the visualization. If it does, please file an issue. You can find the complete code in the following repo. 

## Who, how much and when? {-}

The first visualizations follow very simple questions: Who has made how many statements? How long were these statements? And did the length of the statements change during the debate?

<br>

```{r, include=FALSE}
debate <- read_csv("webscraping/presdebate2020.csv")

theme_set(theme_minimal()) 
theme_update(panel.grid = element_blank(),
             text = element_text(family = "Trebuchet MS"))

debate_clean <- debate %>% 
  filter(!is.na(names)) %>% 
  rename(speaker = names) %>% 
  mutate_all(.funs = tolower) %>% 
  mutate(speaker = case_when(speaker == "president" ~ "trump",
                             speaker == "joe" ~ "biden", 
                             TRUE ~ speaker),
         speaker = recode_factor(speaker,
                         `1` = "trump",
                         `2` = "biden",
                         `3` = "wallace"),
         id = row_number())

fill_values <- c("#950952","#18314F", "darkgrey")
```

```{r}
statements <- debate_clean %>% 
  group_by(speaker) %>% 
  count()

ggplot(data = statements, aes(x = speaker, y = n, fill = speaker)) +
  geom_bar(stat = "identity", width = 0.6) +
  scale_fill_manual(values = fill_values) +
  labs(title = "How many statements?", 
       x = "",
       y = "Number of statements\n") +
  theme(legend.position = "none",
        panel.grid.major.x = element_blank(),
        plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.background = element_rect(fill = "lightgrey", color = "lightgrey"))
```

With 165 statements, Trump had the most and 25 more statements than candidate Biden. However, this number doesn't allow any conclusions about the length of their comments, which is probably more meaningful. It should be pointed out how often Chris Wallace, the moderator, spoke. This probably has its good reasons, but more about this later. 

First, the question arises whether Trump's statements were not only more frequent but also longer. A histogram helps us to examine the comments of the two candidates in more detail.

<br>

```{r, include=FALSE}
number_words <- debate_clean %>% 
  mutate(words = str_count(statements,'\\w+'))

number_words %>% 
  group_by(speaker) %>% 
  summarise(totalwords = sum(words),
            average = mean(words))
```

```{r, echo=FALSE}
number_words %>% 
  filter(speaker != "wallace") %>% 
  select(words, speaker) %>% 
  ggplot(aes(x = words, fill = speaker, color = speaker)) +
  geom_density(alpha = 0.6) +
  scale_fill_manual(values = fill_values) +
  scale_color_manual(values = fill_values) +
  scale_x_continuous(breaks = c(0, 25, 50, 100, 200, 400), labels = c(0, 25, 50, 100, 200, 400)) +
  labs(title = "Distribution of the statements' length",
       y = "Count\n",
    x = "\nNumber of words",
    fill = "", 
    color = "") +
  theme_minimal() +
  theme(text = element_text(family = "Trebuchet MS"),
        legend.position = "top",
        panel.grid = element_blank(),
        plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.background = element_rect(fill = "lightgrey", color = "lightgrey"))
```

Zwei Aspekte werden ersichtlich. Erstens, beide Kandidaten haben nur wenige Statements, die länger als 100 Wörter lang sind. Die meisten Kommentare konzentriere sich um eine Länge von 10-25 Wörtern. Zum Vergleich: Ein durchschnittlicher Satz in der Literatur, obwohl das schwer zu definieren ist, enthält heutzutage zwischen 15-20 Wörter. Die Satzlänge ist in der gesprochenen Sprache deutlich kürzer und variiert von Medium zu Medium, von Gespräch zu Gespräch, aber diese Zahlen zeigen auf, dass die meisten Statements der Kandidaten aus vielleicht zwei, maximal drei Sätzen bestanden. Ein erster Hinweis darauf, wie die Debatte nicht aus längeren Parolen, sondern vielmehr aus kurzen, unterbrochenen Statements bestand. 

Zweitens lässt sich anhand der übereinandergelegten Verteilungen gut erkennen, wie sich die Länge der Kommentare der beiden Kandidaten deutlich unterscheidet. Trump hatte deutlich mehr kürzere Statements als sein Counterpart während Biden mehr Statement im Bereich zwischen 50-100 Wörter hat. Auch dies ein deutlicher Hinweis dafür, wie sich die Debattenkulturen der beiden Kandidaten unterscheiden.

Zuletzt stellt sich die Frage, ob sich die Länge der Statements im Verlauf der geändert hatte. For instance, wurden die Statements, je länger die Debatte dauerte, kürzer? Wie reagierten die Kandidaten auf Remarks des Gegenübers? Der folgende Plot gibt darüber Aufschluss.

<br>

```{r, echo=FALSE}
number_words %>% 
  filter(speaker != "wallace") %>% 
  ggplot(aes(x = id, y = words, group = speaker, color = speaker)) +
  scale_color_manual(values = fill_values) +
  scale_x_continuous(breaks = c(30, 410), labels = c("Start of the debate", "End of the debate")) +
  labs(title = "Length of statements throughout the debate",
       x = "",
       y = "Number of words\n",
       color = "") +
  geom_line() +
  theme(panel.grid = element_blank(),
        legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.background = element_rect(fill = "lightgrey", color = "lightgrey"),
        axis.text.x = element_text(face = "bold")) 
```

Unschwer sind die spikes aus der Grafik herauszulesen, die die sehr langen Statements der beiden Kandidaten ab und wann widerspiegeln. Meistens folgen sie direkt aufeinander. Sprich, entweder reagierte Trump sofort mit einem langen Kommentare auf ein langes Statement von Biden oder umgekehrt. Ausführen, welche Spikes welche Intervention repräsentieren. 

Um diese ersten deskriptiven Grafiken zusammenzufassen: Trump platzierte mehr Statements als Biden, jedoch waren viele davon kürzer als diejenigen des ehemaligen Vizepräsidenten. Die letzte Grafik zeigte auf, dass die Lànge der Statements im Verlauf der Debatte einem klaren Muster folgte. Der eine Kandidat reagierte mit einem langen Kommentar auf ein ausführliches Statements des anderen oder umgekehrt. Dieses Muster zieht sich durch die ganze Debatte hindurch und die Wortlänge verändert sich im Verlauf der Diskussion kaum. 

Wir wissen nun bereits ein wenig, wie die beiden Kandidaten sich präsentiert haben, doch nach wie vor ist unklar, WAS sie überhaupt sagten. Gewissermassen war der Inhalt der Parolen durch die verschiedenen thematischen Segmente vorgegeben, aber dennoch lässt dies grossen Spielraum, um die Persänlichkeit der beiden Kontrahenten anhand ihrer Aussagen genauer zu entschlüsseln. 

Entsprechend versucht der folgende Abschnitt die inhaltliche Ebene der Debatte zu durchleuchten. Dafür plotte ich anfänglich die krude Statistik der meistgenannten Wörter, bevor fortgeschrittenere Methoden wie die "textual keyness" Aufschluss darüber geben, welche Wörter besonders personen-spezifisch verwendet wurden. Zuletzt zeigen Netzwerke die co-occurences der Wörter in den Statements der beiden Kandidaten auf.

## What exactly? {-}

Zunächst konzentrieren wir uns auf einen sehr kruden Messwert - die Worthäufigkeit. Im obigen Plot sind jeweils die 10 meistbenutzen Wörter der beiden Kandidaten aufgeführt. Bei beiden kommen die "people" an erster Stelle. Bei Biden, sofern das anhand der 10 meistbenutzen Wörter möglich ist, lässt sich eine gewisse (dringende) Tatkraft erkennen: "going" spielt auf zukünftige actions an, genauso die Wörter "deal" und "now". Ausserdem ist interessant, wie -- nachdem die stopwords entfernt wurden -- das Wort "fact" am drittmeisten von Kandidaten Biden benutzt wurde. War das Absicht angesichts der Tatsache, dass bei Trump schnell der Verdacht nach Fake News vorkommt?

```{r, include=FALSE}
#preparing the corpus of the whole debate

debate_corpus_df <- debate_clean %>% 
  group_by(speaker) %>% 
  summarise(statements = paste(statements, collapse = "")) %>% 
  filter(speaker != "wallace") %>% 
  mutate(speaker_name = speaker)

debate_corpus <- corpus(debate_corpus_df, docid_field = "speaker_name",
  text_field = "statements")

summary(debate_corpus)

dfm_debate <- debate_corpus %>% 
  tokens(remove_punct = TRUE,
         remove_symbols = FALSE,
         remove_numbers = FALSE) %>% 
  tokens_remove(pattern = stopwords("en")) %>% 
  dfm()

topfeatures(dfm_debate, 10)

#preparing the corpus for biden

biden_corpus <- corpus_subset(debate_corpus, speaker == "biden")

dfm_biden <- biden_corpus %>% 
  tokens(remove_punct = TRUE,
         remove_symbols = FALSE,
         remove_numbers = FALSE) %>% 
  tokens_remove(pattern = stopwords("en")) %>% 
  dfm()

biden_top10 <- as_tibble(topfeatures(dfm_biden, 10), rownames = "word")

#preparing the corpus for trump

trump_corpus <- corpus_subset(debate_corpus, speaker == "trump")

dfm_trump <- trump_corpus %>% 
  tokens(remove_punct = TRUE,
         remove_symbols = FALSE,
         remove_numbers = FALSE) %>% 
  tokens_remove(pattern = stopwords("en")) %>% 
  dfm()

trump_top10 <- as_tibble(topfeatures(dfm_trump, 10), rownames = "word")
```

```{r}
# plotting biden's top 10 

plot_biden10 <- ggplot(data = biden_top10, aes(x = fct_reorder(word, value), y = value)) +
  geom_bar(stat = "identity", fill = "#18314F") +
  labs(title = "Biden's Top 10 Words\n",
       y = "\nNumber of Occurences",
       x = "") +
  coord_flip() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# plotting trump's top 10 
plot_trump10 <- ggplot(data = trump_top10, aes(x = fct_reorder(word, value), y = value)) +
  geom_bar(stat = "identity", fill = "#950952") +
  labs(title = "Trumps's Top 10 Words\n",
       y = "\nNumber of Occurences",
       x = "") +
  coord_flip() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

plot_biden10 + plot_trump10 +
  plot_layout(ncol = 2, guides = "collect") & theme(plot.background = element_rect(fill = "lightgrey", color = "lightgrey"))
```

Die meistbenutzen Wörtern des Präsidenten wiederum lassen in dieser Form ohne Kontext wenig Rückschlüsse zu. Die Wörter "want", "look", "know", "said", aber auch die anderen Wörter können in ganz unterschiedlichen Zusammenhängen verwendet werden, weswegen Interpretationen an dieser Stelle verfrüht wären. 

Gehen wir deshalb einen Schritt weiter und schauen uns einen sogennanten "keyness"-Plot an. Sehr vereinfacht gesagt, bedeutet "Keyness" in diesem Fall, wie kandidaten-spezifisch ein gewisses Wort ist. Je höher der absolute Wert von Chi Square ist, desto kandidatenspezifischer ist das entsprechende Wort. Hier lassen sich bereits einige interessante Tendenzen erkennen. 

Das Trump-spezifischste Wort ist "joe". Dies kommt nicht überraschend. Wer die Debatte geschaut hat, wird sich daran erinnern, wie oft der Präsident seinen Kontrahenten mit seinem Vornamen angesprochen. Zwar nicht abgebildet, aber unter den "typischsten" Trump-Wörter kommt auch "chris" vor, also der Name des Moderators. Trump's direkte Art wird also auch in dieser Debatte klar ersichtlich bzw. hörbar. Ausserdem fällt auf, dass das Wort "country" fast nur im Zusammenhang mit Trump's statements fällt. Entsprechend ist es an zweiter Stelle des "keyness"-Plots aufgeführt. Wenn man die Parolen genauer betrachtet, erkennt man, dass das Wort "years" zweideutig ist bei Trump. Einerseits braucht er es, um aufzuzeigen, wie viel das er in den vier Jahren gemacht (ein anderen Trump-spezifisches Wort) hat. Andererseits braucht er es aber auch, um Biden als Versager hinzustellen. Einige Mal erwähnte Trump, wie Biden in diesen vielen Jahr nichts erreicht habe. 

Und wie schaut es bei Biden aus? Wie bereits im obigen Plot fällt das Wort "fact" sofort ins Auge. Biden benutzte dieses Wort 37 mal, Trump kein einziges Mal. Entsprechend steht es an erster Stelle der Biden-spezifischen Wörter. 

```{r, fig.height=8, fig.width=8, fig.retina=3}
#keyness plot

tstat_key <- textstat_keyness(dfm_debate)
textplot_keyness(tstat_key, n = 10, font = "Trebuchet MS", color = fill_values) +
  labs(title = "Keyness",
       x = "\nChi Square",
       y = "") +
  scale_y_continuous(breaks = seq(0, 30, 15), labels = c(15, 0, 30)) +
  theme_minimal() +
  theme(panel.grid = element_blank(),
        legend.position = "right",
        plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.background = element_rect(fill = "lightgrey", color = "lightgrey"),
        text = element_text(family = "Trebuchet MS"))
```

```{r}
# creating a network

# biden

fcm_biden <- fcm(dfm_biden)
feat_biden <- names(topfeatures(fcm_biden, 30))
set.seed(133)
fcm_select(fcm_biden, pattern = feat_biden) %>%
    textplot_network(min_freq = 0.75,
                     edge_color = "#18314F",
                     edge_alpha = 0.3,
                     vertex_labelfont = "Trebuchet MS") +
  theme(plot.background = element_rect(fill = "lightgrey"))

# trump

fcm_trump <- fcm(dfm_trump)
feat_trump <- names(topfeatures(fcm_trump, 30))
set.seed(133)
fcm_select(fcm_trump, pattern = feat_trump) %>%
    textplot_network(min_freq = 0.75,
                     edge_color = "#950952",
                     edge_alpha = 0.3,
                     vertex_labelfont = "Trebuchet MS",
                     vertex_color = "black", 
                     vertex_labelsize = 3) +
  ggtitle("Network of Trump's most frequent words\n") +
  theme(plot.background = element_rect(fill = "lightgrey", color = "lightgrey"),
        plot.title = element_text(hjust = 0.5, size = 15, face = "bold"))
```

## What's next? {-}

Dieser Beitrag repräsentiert nur einen sehr kleinen Teil der Vielzahl an Möglichkeiten, die Textdaten dieser Debatte offerieren. Beispielsweise versuchte ich mit einem unsupervised model (LDA) verschiedenene Topics der Debatte zu extrahieren, doch nach einigen Schwierigkeiten liess ich es dabei sein. Abgesehen von den Netzwerkplots habe ich die Texte als "bag-of-words" behandelt. Sprich, die realtive Position der Wörter in den Sätzen habe ich aktuell nicht berücksichtigt. Diese würde bestimmte auch einige interessante Fragen beantworten. 

Mit dem öffentlich zugänglichen Code möchte ich Leute dazu ermutigen, zur Analyse beizutragen, um weitere interessante Einblick in die (fehlende?) Debattenkultur der Präsidentschaftskandidaten zu gewinnen. Entweder kann man direkt ein Issue im entsprechenden Repository ablegen oder dann das Repository klonen und die Analyse selber erweitern. 

In diesem Sinne hoffe ich, einen etwas, wenn auch doch eher oberflächlichen, differenzierten Einblick in die ersten 2020 Präsidentschaftsdebatte gewährt haben zu können. Ob und wie sich das Debattenformat für die zukünftigen Gegenübertreffen ändern werden, kann ich nicht beeinflussen. Ich bin aber bereits zufrieden, wenn ich einige Leute mit diesem Beitrag dazu anregen konnte, eigene Fragen mithilfe der mit R zu Verfügung stehenden Tools beantworten könnne. 

```{r, echo=FALSE}
rolldown::scrollama_setup(
  list(step = '.level1', offset = .2, debug = F)
)
```
